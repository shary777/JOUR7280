{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JOUR7280/COMM7780 Big Data Analytics for Media and Communication\n",
    "# Tutorial: Python Web Scraping Using BeautifulSoup\n",
    "In this tutorial, you will learn how to perform web scraping using Python 3 and the `BeautifulSoup` library. We’ll be scraping weather forecasts from the [National Weather Service](https://www.weather.gov/), and then store data using the Pandas library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `requests` library will make a `GET` request to a web server, which will download the HTML contents of a given web page for us.  \n",
    "After running our request, we get a `Response` object. This object has a `status_code` attribute, 200 indicates the page was downloaded successfully"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "url = 'https://forecast.weather.gov/MapClick.php?lat=37.7772&lon=-122.4168'\n",
    "page = requests.get(url)\n",
    "page"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can print out the HTML content of the page using the `content` attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing a page with BeautifulSoup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(page.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring page structure with Chrome DevTools\n",
    "We’ll extract weather information about downtown San Francisco from [this page](http://forecast.weather.gov/MapClick.php?lat=37.7772&lon=-122.4168).  \n",
    "The first thing we’ll need to do is inspect the page using Chrome developer tools. Start the developer tools in Chrome by clicking `More Tools` -> `Developer Tools`  \n",
    "<img src=\"../figs/dev.png\" alt=\"drawing\" width=\"550\"/>\n",
    "### Finding all instances of a tag at once\n",
    "If we want to extract a single tag, we use the `find_all` method, which will find all the instances of a tag on a page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "soup.find_all('title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find_all('h2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you instead only want to find the **first** instance of a tag, you can use the `find` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find('h2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Structure of  Extended Forecast\n",
    "By right clicking on the page near where it says “Extended Forecast”, then clicking “Inspect”, we’ll open up the tag that contains the text “Extended Forecast” in the elements panel.  \n",
    "The `div` contains the extended forecast items.\n",
    "If you explore the div, you’ll discover that each forecast item (like “Tonight”, “Thursday”, and “Thursday Night”) is contained in a div with the class `tombstone-container`.\n",
    "<img src=\"../figs/inspect.png\" alt=\"drawing\" width=\"550\"/>\n",
    "\n",
    "In the below code, we:\n",
    "- Download the web page containing the forecast.\n",
    "- Create a BeautifulSoup class to parse the page.\n",
    "- Find the div with id `seven-day-forecast`, and assign to variable seven_day\n",
    "- Inside seven_day, find each individual forecast item.\n",
    "- Extract and print the first forecast item."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and parse the web page\n",
    "page = requests.get(\"http://forecast.weather.gov/MapClick.php?lat=37.7772&lon=-122.4168\")\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "seven_day = soup.find(id=\"seven-day-forecast\") # Find seven-day-forecast\n",
    "forecast_items = seven_day.find_all(class_=\"tombstone-container\")\n",
    "tonight = forecast_items[0] # extract 1st forecast\n",
    "print(tonight.prettify()) # Pretty-print this PageElement as a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print every forecast item\n",
    "for item in forecast_items:\n",
    "    print(item.prettify(), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting information from the page\n",
    "As you can see, inside the forecast item `tonight` (variable) is all the information we want. There are 4 pieces of information we can extract:\n",
    "- The name of the forecast item \n",
    "- The description of the conditions — this is stored in the title property of img.\n",
    "- A short description of the conditions \n",
    "- The temperature low/high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# extract the name of the forecast item, the short description, and the temperature\n",
    "period = tonight.find(class_=\"period-name\").get_text()\n",
    "short_desc = tonight.find(class_=\"short-desc\").get_text()\n",
    "temp = tonight.find(class_=\"temp\").get_text()\n",
    "print(period)\n",
    "print(short_desc)\n",
    "print(temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can extract the `title` attribute from the *img* tag. To do this, we just treat the variable `img` like a <span style=\"color:orange\">dictionary</span>, and extract the attribute we want as a key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract a short description of the conditions\n",
    "img = tonight.find(\"img\")\n",
    "desc = img['title']\n",
    "print(desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting all the information from the page\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we search for items with the class `period-name` and store them to a list.\n",
    "\n",
    "The way to make a list here is called **List Comprehensions**. Rather than creating an empty list and adding each element to the end, you simply define the list and its contents at the same time. See more [here](https://realpython.com/list-comprehension-python/#using-list-comprehensions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "periods = [day.text for day in seven_day.find_all(class_='period-name')]\n",
    "periods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the same technique to get the other `3` fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "short_descs = [sd.text for sd in seven_day.find_all(class_='short-desc')]\n",
    "temps = [temp.text for temp in seven_day.find_all(class_='temp')]\n",
    "descs = [img['title'] for img in seven_day.find_all('img')]\n",
    "\n",
    "print(short_descs)\n",
    "print(temps)\n",
    "print(descs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining our data into a Pandas Dataframe\n",
    "We pass `4` lists into `pd.DataFrame` as part of a dictionary. Each dictionary key will become a column in the DataFrame, and each list will become the values in the column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create a dataframe\n",
    "weather = pd.DataFrame({\n",
    "    \"period\": periods,\n",
    "    \"short_desc\": short_descs,\n",
    "    \"temp\": temps,\n",
    "    \"desc\":descs\n",
    "})\n",
    "weather"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the dataframe to a `csv` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather.to_csv('../data/weather.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape images \n",
    "\n",
    " - **please proceed with caution and always check the terms of use!!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see there are several images. Images are displayed with the \\< img \\> tag in HTML.\n",
    "\n",
    "Next, let's scrape all the weather images and save them to '../figs' folder.\n",
    "\n",
    "Previously, we have founded all the `img` tags in 7 day forcast. The `src` attribute contains the link of image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for img in seven_day.find_all('img'):\n",
    "#     img_url = img.get('src')\n",
    "    img_url = img['src']\n",
    "    print(img_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The links are not complete, lack of domain: https://forecast.weather.gov/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "img_urls = []\n",
    "domain = 'https://forecast.weather.gov/'\n",
    "for img in seven_day.find_all('img'):\n",
    "    img_url = domain + img.get('src')\n",
    "    img_urls.append(img_url)\n",
    "    print(img_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To downloads and save files with Python, we use the shutil library which is a file operations library.\n",
    "It is always good to add a **time delay** via the `time.sleep` function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "import time \n",
    "from random import randint\n",
    "\n",
    "\n",
    "for img_url in img_urls: \n",
    "    \n",
    "    # time.sleep(5) # a fixed rate (delay 5 sec)\n",
    "    time.sleep(randint(2,6))  # a random int delay between 2 to 6 sec \n",
    "    \n",
    "    # we set stream = True to download/stream the content of the data\n",
    "    img_source = requests.get(img_url, stream=True) \n",
    "    \n",
    "    # open file connection, create file and write to it\n",
    "    # 'wb': write and binary\n",
    "    with open('../figs/'+img_url.split('/')[-1], 'wb') as file: \n",
    "        # save the raw file object, see the tutorial: https://docs.python.org/3/library/shutil.html\n",
    "        shutil.copyfileobj(img_source.raw, file) \n",
    "        \n",
    "    del img_source # to remove the file from memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The codes in this notebook are modified from various sources. All codes are for educational purposes only and released under the CC1.0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
